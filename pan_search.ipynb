{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0e629ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "# session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87f9e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRY_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ae0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanSearch:\n",
    "    \n",
    "    def __init__(self,pan):\n",
    "        \n",
    "        self.pan = pan\n",
    "        self.url_link = \"https://www.karvykra.com/UPanSearchGlobalWithPanExempt.aspx\"\n",
    "        self.user_Agent =\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\"\n",
    "        \n",
    "    def encode_pan_number(self,pan):\n",
    "        \n",
    "        # we append few characters to the original pan which is further passed for b64 encoding \n",
    "        def append_char_to_pan(pan):\n",
    "            a_pan = \"#\"+pan[0]+\"xX\"+pan[1]+\"M\"+pan[2]+\"gX\"+pan[3]+\"i\"+pan[4]+\"ta\"+pan[5:7]+\"v\"+pan[7:9]+\"yt\"+pan[9]\n",
    "            return a_pan\n",
    "        \n",
    "        txtpanNo = append_char_to_pan(pan)\n",
    "        conv_bytes = txtpanNo.encode()\n",
    "        b64_bytes = base64.b64encode(conv_bytes)\n",
    "        encoded_pan_num = b64_bytes.decode()\n",
    "        #return the encoded pan\n",
    "        return encoded_pan_num\n",
    "    \n",
    "    def home_page(self):\n",
    "        \n",
    "        headers = {\n",
    "            \n",
    "            \"User-Agent\":self.user_Agent\n",
    "        }\n",
    "        response = session.get(self.url_link,headers = headers)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            return \"No Response\"\n",
    "        \n",
    "    def parse_with_lxml(self,home_page_response):\n",
    "        #we parse the html code with lxml\n",
    "        soup = BeautifulSoup(home_page_response.text,'lxml')\n",
    "        return soup\n",
    "    \n",
    "    \n",
    "    def get_payload_Var(self,soup):\n",
    "        #we extract the required varibales and return them \n",
    "        __VIEWSTATE = soup.find('input',attrs={'id':'__VIEWSTATE'})[\"value\"]\n",
    "        __VIEWSTATEGENERATOR = soup.find('input',attrs={'id':'__VIEWSTATEGENERATOR'})['value']\n",
    "        __EVENTVALIDATION = soup.find('input',attrs= {'id':'__EVENTVALIDATION'})['value']\n",
    "        \n",
    "        return __VIEWSTATE,__VIEWSTATEGENERATOR,__EVENTVALIDATION\n",
    "    \n",
    "    def get_captcha_image(self,soup):\n",
    "        #extract the div tag from the soup\n",
    "        d = soup.find('div',attrs={'style':'background-color:White;color:White;'})\n",
    "        #extract the image tag with its sourcelink\n",
    "        img_src = d.img['src']\n",
    "        #concatinate with the domain \n",
    "        img_link = \"https://www.karvykra.com/\"+img_src\n",
    "        #fetch the image \n",
    "        img = session.get(img_link)\n",
    "        #path where the image is stored\n",
    "        PATH = '/home/nagaraj/Desktop/Nag/NK/Web-Crawl/Captchas/pansearch.jpeg'\n",
    "        #save the captcha in the path\n",
    "        with open(PATH,'wb') as f:\n",
    "            f.write(img.content)\n",
    "        return PATH\n",
    "    \n",
    "    def get_text_from_image(self,PATH):\n",
    "        import cv2\n",
    "        from pytesseract import pytesseract\n",
    "        from pytesseract import Output\n",
    "        img = cv2.imread(PATH)\n",
    "        # img=cv2.resize(img,(900,1200))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))\n",
    "        thresh=cv2.dilate(gray,rect_kernel,iterations=1)\n",
    "        image_data = pytesseract.image_to_data(thresh, output_type=Output.DICT)\n",
    "        captcha_Str = \"\"\n",
    "        for i, word in enumerate(image_data['text']):\n",
    "            if word != '':\n",
    "                captcha_Str = captcha_Str+word\n",
    "        return captcha_Str\n",
    "        \n",
    "    def fetch_data(self,VIEWSTATE,VIEWSTATEGENERATOR,EVENTVALIDATION,input_pan,captcha_text):\n",
    "        \n",
    "        headers = {\n",
    "            \n",
    "            \"User-Agent\":self.user_Agent,\n",
    "            \"Origin\":\"https://www.karvykra.com\",\n",
    "            \"Referer\":\"https://www.karvykra.com/UPanSearchGlobalWithPanExempt.aspx\",\n",
    "            \"Content-Type\":\"application/x-www-form-urlencoded\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \n",
    "            \"__EVENTTARGET\":\"\",\n",
    "            \"__EVENTARGUMENT\":\"\",\n",
    "            \"__VIEWSTATE\":VIEWSTATE,\n",
    "            \"__VIEWSTATEGENERATOR\":VIEWSTATEGENERATOR,\n",
    "            \"__EVENTVALIDATION\":EVENTVALIDATION,\n",
    "            \"txtpanNo\":input_pan,\n",
    "            \"txtItnrMdtCapcha\":captcha_text,\n",
    "            \"btnSearch\":\"Search Now\"\n",
    "        }\n",
    "        \n",
    "        #fetching the data with the post request\n",
    "        response = session.post(self.url_link,headers=headers,data=payload)\n",
    "        return response\n",
    "    \n",
    "    def extract_data(self,soup):\n",
    "        \n",
    "        #this func converts the list into the dictionary\n",
    "        def Convert(a):\n",
    "            it = iter(a)\n",
    "            res_dct = dict(zip(it, it))\n",
    "            return res_dct\n",
    "        #this func extracts the tables contents \n",
    "        def get_table_data(table):\n",
    "            #get all the table headings and store it in the headers var\n",
    "            headers = [th.text.strip() for th in table.find_all('th')]\n",
    "            #get all the tables rows\n",
    "            rows = table.find_all('tr')\n",
    "            data = [] #initialize an empty list \n",
    "            \n",
    "            #loop through the tr's and extract the td\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if cells:\n",
    "                    items = {headers[i]: cells[i].text.strip() for i in range(len(headers))}\n",
    "                    data.append(items)\n",
    "            return data\n",
    "        #find the table in the html using the id attribute\n",
    "        table = soup.find(\"table\",attrs={\"id\":\"PanDetails\"})\n",
    "        items= []\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cols=row.find_all('td')\n",
    "            cols=[x.text.strip('\\n') for x in cols]\n",
    "            items.append(cols)\n",
    "        #the above generates list and we require only the 5,6,7 elements in the list\n",
    "        r1 = Convert(items[5])\n",
    "        r2 = Convert(items[6])\n",
    "        r3 = Convert(items[7])\n",
    "        r3.pop('') #pop the empty key value pair \n",
    "        dict1 = {**r1, **r2, **r3} #merge all the three dictionaries\n",
    "        \n",
    "        #find the table in the html using the id attribute\n",
    "        table2 = soup.find('table',attrs={'id':'GridView1'})\n",
    "        \n",
    "        val = get_table_data(table2)\n",
    "        additionalDetails = val[1]\n",
    "        result = {\n",
    "            \"krastatus\": dict1,\n",
    "            \"additionalDetails\": [additionalDetails]\n",
    "        }\n",
    "        #returning the result\n",
    "        return json.dumps({\"result\":result},indent=4)\n",
    "        \n",
    "        \n",
    "    def get_output(self):\n",
    "        \n",
    "        for retry_num in range(RETRY_COUNT):\n",
    "            \n",
    "            #this initializes a session for each request\n",
    "            self.session = requests.session()\n",
    "            \n",
    "            #here in this site we need to enter the pan number in the encoded form\n",
    "            #so we call the 'encode_pan_number' func.\n",
    "            input_pan = self.encode_pan_number(self.pan)\n",
    "            \n",
    "            #we call the landing page to get the initial response\n",
    "            home_page_response = self.home_page()\n",
    "            \n",
    "            #we parse the fetched html data using the lxml\n",
    "            parsed_data = self.parse_with_lxml(home_page_response)\n",
    "            \n",
    "            #the website requires few variables as payload so we fetch these variables\n",
    "            VIEWSTATE,VIEWSTATEGENERATOR,EVENTVALIDATION = self.get_payload_Var(parsed_data)\n",
    "            \n",
    "            #get the captcha image from the site and store it in a particular location\n",
    "            captcha_response_path = self.get_captcha_image(parsed_data)\n",
    "            \n",
    "            #now extract the letters in the captcha using the func 'get_text_from_image'\n",
    "#             captcha_text = self.get_text_from_image(captcha_response_path)\n",
    "            \n",
    "            captcha_text = input(\"Enter the Captcha code : \")\n",
    "        \n",
    "            #now pass the id and captcha as params for the post request to fetch the data\n",
    "            second_response = self.fetch_data(VIEWSTATE,VIEWSTATEGENERATOR,EVENTVALIDATION,input_pan,captcha_text)\n",
    "            \n",
    "            #now parse the response with the lxml \n",
    "            second_soup = self.parse_with_lxml(second_response)\n",
    "\n",
    "            \n",
    "            #extract the requried table contents \n",
    "            output = self.extract_data(second_soup)\n",
    "            \n",
    "            return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0046fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Captcha code : EP2WK\n",
      "{\n",
      "    \"result\": {\n",
      "        \"krastatus\": {\n",
      "            \"Status as on :\": \"Mar 28, 2023 12:21:21\",\n",
      "            \"KYC Flag : \": \"\",\n",
      "            \"PAN:\": \"CAGPN9774A\",\n",
      "            \"eSIGN Flag : \": \"\",\n",
      "            \"IPV Flag :\": \"IPV Exempt\"\n",
      "        },\n",
      "        \"additionalDetails\": [\n",
      "            {\n",
      "                \"KRA\": \"CVL\",\n",
      "                \"Date Of Upload\": \"30-11-2021 11:47:32\",\n",
      "                \"Status\": \"02\",\n",
      "                \"Status Description\": \"KYC Registered\",\n",
      "                \"Status Date\": \"04-12-2021 14:31:46\",\n",
      "                \"Date Of Modification\": \"\",\n",
      "                \"Modify Status\": \"Not Available\",\n",
      "                \"Modify Hold Reasons\": \"\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(PanSearch(\"CAGPN9774A\").get_output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98329512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
